{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, MACCSkeys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from rdkit.Chem import rdmolops\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21 = pd.read_csv('data/tox21.csv')\n",
    "smiles_list = tox21['SMILES'].tolist()\n",
    "label_columns = ['SR-HSE','NR-AR', 'SR-ARE', 'NR-Aromatase', 'NR-ER-LBD', 'NR-AhR', 'SR-MMP',\\\n",
    "       'NR-ER', 'NR-PPAR-gamma', 'SR-p53', 'SR-ATAD5', 'NR-AR-LBD']\n",
    "targets = tox21[label_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for Feature Extraction\n",
    "def compute_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    descriptors = {\n",
    "        \"MolecularWeight\": Descriptors.MolWt(mol),\n",
    "        \"LogP\": Descriptors.MolLogP(mol),\n",
    "        \"HBD\": Descriptors.NumHDonors(mol),\n",
    "        \"HBA\": Descriptors.NumHAcceptors(mol),\n",
    "        \"TPSA\": Descriptors.TPSA(mol),\n",
    "    }\n",
    "    return descriptors\n",
    "\n",
    "def compute_fingerprints(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048)\n",
    "    maccs_fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "    return {\n",
    "        \"MorganFP\": list(morgan_fp),\n",
    "        \"MACCSFP\": list(maccs_fp),\n",
    "    }\n",
    "\n",
    "def compute_graph_features(graph):\n",
    "    features = {\n",
    "        \"AverageDegree\": sum(dict(graph.degree()).values()) / len(graph.nodes()),\n",
    "        \"Density\": nx.density(graph),\n",
    "        \"ClusteringCoefficient\": nx.average_clustering(graph),\n",
    "    }\n",
    "    if nx.is_connected(graph):\n",
    "        features[\"Diameter\"] = nx.diameter(graph)\n",
    "    else:\n",
    "        features[\"Diameter\"] = None\n",
    "    return features\n",
    "\n",
    "def compute_node2vec_embeddings(graph, dimensions=64):\n",
    "    node2vec = Node2Vec(graph, dimensions=dimensions, walk_length=30, num_walks=50, workers=12, seed=42)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    \n",
    "    node_embeddings = np.array([model.wv[str(node)] for node in graph.nodes()])\n",
    "    graph_embedding = node_embeddings.mean(axis=0)  \n",
    "    return graph_embedding\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    adjacency_matrix = rdmolops.GetAdjacencyMatrix(mol)\n",
    "    graph = nx.from_numpy_array(adjacency_matrix)\n",
    "    for i, atom in enumerate(mol.GetAtoms()):\n",
    "        graph.nodes[i]['atom_type'] = atom.GetSymbol()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/features.csv'):\n",
    "    features = []\n",
    "    for smile in tqdm(smiles_list):\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smile)\n",
    "            graph = smiles_to_graph(smile)\n",
    "            \n",
    "            descriptors = compute_descriptors(smile)\n",
    "            fingerprints = compute_fingerprints(smile)\n",
    "            graph_features = compute_graph_features(graph)\n",
    "            node2vec_embeddings = compute_node2vec_embeddings(graph)\n",
    "            \n",
    "            combined_features = {**descriptors, **fingerprints, **graph_features, **{f\"Node2Vec{i}\": node2vec_embeddings[i] for i in range(len(node2vec_embeddings))}}\n",
    "            features.append(combined_features)\n",
    "        except Exception as e:\n",
    "            print(f\"Tus muertos pisados {smile}: {e}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    feature_df = pd.DataFrame(features)\n",
    "    feature_df.to_csv('data/features.csv', index=False)\n",
    "else:\n",
    "    feature_df = pd.read_csv('data/features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_df.drop(\n",
    "#    ['MorganFP', 'MACCSFP'], axis=1, inplace=True\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "morgan = feature_df['MorganFP']\n",
    "maccs = feature_df['MACCSFP']\n",
    "feature_df.drop(['MorganFP', 'MACCSFP'], axis=1, inplace=True)\n",
    "\n",
    "iterative_imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "targets = pd.DataFrame(iterative_imputer.fit_transform(targets), columns=targets.columns)\n",
    "feature_df = pd.DataFrame(iterative_imputer.fit_transform(feature_df), columns=feature_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_df = pd.DataFrame(df[: , :feature_df.shape[1]] , columns=feature_df.columns)\n",
    "#targets = pd.DataFrame(df[: , feature_df.shape[1]:] , columns=targets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.map(lambda x: 1 if x >= .5 else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, f1_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = MultiOutputClassifier(XGBClassifier(n_estimators=1000, max_depth=6, learning_rate=0.1, n_jobs=-1, random_state=42, scale_pos_weight=10, enable_categorical = True, eval_metric = 'logloss'), n_jobs=-1)\n",
    "\n",
    "\n",
    "X,y = feature_df, targets.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "Y = pd.DataFrame()\n",
    "\n",
    "for column in y_train.columns:\n",
    "    target_column = y_train[column]\n",
    "    oversampler = SMOTE(random_state=42)\n",
    "    _, y_resampled = oversampler.fit_resample(X_train, target_column)\n",
    "    oversampled_data.append((X_resampled, y_resampled))\n",
    "\n",
    "\n",
    "feature_df['MorganFP'] = morgan\n",
    "feature_df['MACCSFP'] = maccs\n",
    "feature_df['MACCSFP'] = feature_df['MACCSFP'].astype('category')\n",
    "feature_df['MorganFP'] = feature_df['MACCSFP'].astype('category')\n",
    "\n",
    "X_train = pd.DataFrame(oversampled_data[0][0], columns=X_train.columns)\n",
    "y_train = pd.DataFrame({column: y for _, y in oversampled_data}, columns=y_train.columns)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Balanced dataset shape {Counter(y_train)}\")\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#X_train_2d = pca.fit_transform(X_train)\n",
    "\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_train, y_train, test_size=0.01, random_state=42)\n",
    "#X_train = pd.concat([X_train, X_train_80, X_test_80, X_test], axis=0)\n",
    "#y_train = pd.concat([y_train, y_train_80, y_test_80, y_test], axis=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "f1_scores = []\n",
    "for i, column in enumerate(y.columns):\n",
    "    f1 = f1_score(y_test.iloc[:, i], y_pred[:, i], average=\"macro\", zero_division=0)\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"F1-Score for {column}: {f1:.4f}\")\n",
    "    \n",
    "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "print(f\"\\nMean F1-Score across all outputs: {mean_f1:.4f}\")\n",
    "\n",
    "for i, column in enumerate(y.columns):\n",
    "    print(f\"\\nClassification Report for {column}:\\n\")\n",
    "    print(classification_report(y_test.iloc[:, i], y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "mat = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (ax, label) in enumerate(zip(axes, label_columns)):\n",
    "    sns.heatmap(mat[i], annot=True, fmt='d', ax=ax, cmap='coolwarm', cbar=False)\n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
